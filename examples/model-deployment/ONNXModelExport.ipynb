{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c050bd7",
   "metadata": {},
   "source": [
    "<!-- Copyright Vespa.ai. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root. -->\n",
    "\n",
    "### ONNX Model export\n",
    "This is an implementation of [Data analysis with PyTorch and Windows ML](https://learn.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-analysis-intro) - refer to this tutorial for the steps in this notebook.\n",
    "Thanks to Microsoft for creating this tutorial!\n",
    "\n",
    "The code is changed to use the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "from [scikit-learn](https://scikit-learn.org/stable/index.html#).\n",
    "\n",
    "Install dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install pandas torchvision torchaudio scikit-learn onnx\n",
    "!mkdir -p models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bbd82e",
   "metadata": {},
   "source": [
    "Load the Iris data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn import datasets\n",
    "\n",
    "# Loading the Data\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['Iris_Type_num'] = iris.target\n",
    "print('Take a look at sample from the dataset:')\n",
    "print(df.head())\n",
    "\n",
    "print('\\nOur dataset is balanced and has the following values to predict:')\n",
    "print(df['Iris_Type_num'].value_counts())\n",
    "\n",
    "# Convert Iris species into numeric types: Iris-setosa=0, Iris-versicolor=1, Iris-virginica=2\n",
    "labels = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b207b",
   "metadata": {},
   "source": [
    "Define input and output datasets, convert input and output data to Tensors and create a TensorDataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = df.iloc[:, 0:4]              # 4 data columns first\n",
    "print('\\nInput values are:')\n",
    "print(input.head())\n",
    "output = df.loc[:, 'Iris_Type_num']  # output is the Iris_Type_num column\n",
    "print('\\nThe output value is:')\n",
    "print(output.head())\n",
    "\n",
    "input = torch.Tensor(input.to_numpy())               # Create tensor of type torch.float32\n",
    "print('\\nInput format: ', input.shape, input.dtype)  # Input format: torch.Size([150, 4]) torch.float32\n",
    "output = torch.tensor(output.to_numpy())             # Create tensor type torch.int64\n",
    "print('Output format: ', output.shape, output.dtype) # Output format: torch.Size([150]) torch.int64\n",
    "\n",
    "data = TensorDataset(input, output)  # Create a torch.utils.data.TensorDataset object for further data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aae38a",
   "metadata": {},
   "source": [
    "Split to Train, Validate and Test sets using random_split.\n",
    "Then create Dataloader to read the data within batch sizes and put into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 10\n",
    "number_rows = len(input)    # The size of our dataset or the number of rows in the Iris data.\n",
    "test_split = int(number_rows*0.3)\n",
    "validate_split = int(number_rows*0.2)\n",
    "train_split = number_rows - test_split - validate_split\n",
    "\n",
    "train_set, validate_set, test_set = random_split(data, [train_split, validate_split, test_split])\n",
    "\n",
    "train_loader    = DataLoader(train_set, batch_size = train_batch_size, shuffle = True)\n",
    "validate_loader = DataLoader(validate_set, batch_size = 1)\n",
    "test_loader     = DataLoader(test_set, batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333bc5e",
   "metadata": {},
   "source": [
    "Define model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = list(input.shape)[1]   # = 4. The input depends on how many features we initially feed the model.\n",
    "                                    # In our case, there are 4 features for every predict value\n",
    "learning_rate = 0.01\n",
    "output_size = len(labels)           # The output is prediction results for three types of Irises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc2559",
   "metadata": {},
   "source": [
    "Define the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_size, 24)\n",
    "        self.layer2 = nn.Linear(24, 24)\n",
    "        self.layer3 = nn.Linear(24, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.layer1(x))\n",
    "        x2 = F.relu(self.layer2(x1))\n",
    "        x3 = self.layer3(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccbc3da",
   "metadata": {},
   "source": [
    "Instantiate the model, define the execution device, create function to save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223841f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(input_size, output_size)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"The model will be running on\", device, \"device\\n\")\n",
    "model.to(device)    # Convert model parameters and buffers to CPU or Cuda\n",
    "\n",
    "def saveModel():\n",
    "    path = \"./NetModel.pth\"\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32135b",
   "metadata": {},
   "source": [
    "Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f759e1",
   "metadata": {},
   "source": [
    "Define the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    print(\"Begin training...\")\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        running_train_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        running_vall_loss = 0.0\n",
    "        total = 0\n",
    "\n",
    "        # Training Loop\n",
    "        for data in train_loader:\n",
    "            #for data in enumerate(train_loader, 0):\n",
    "            inputs, outputs = data  # get the input and real species as outputs; data is a list of [inputs, outputs]\n",
    "            optimizer.zero_grad()   # zero the parameter gradients\n",
    "            predicted_outputs = model(inputs)   # predict output from the model\n",
    "            train_loss = loss_fn(predicted_outputs, outputs)   # calculate loss for the predicted output\n",
    "            train_loss.backward()   # backpropagate the loss\n",
    "            optimizer.step()        # adjust parameters based on the calculated gradients\n",
    "            running_train_loss +=train_loss.item()  # track the loss value\n",
    "\n",
    "        # Calculate training loss value\n",
    "        train_loss_value = running_train_loss/len(train_loader)\n",
    "\n",
    "        # Validation Loop\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for data in validate_loader:\n",
    "                inputs, outputs = data\n",
    "                predicted_outputs = model(inputs)\n",
    "                val_loss = loss_fn(predicted_outputs, outputs)\n",
    "\n",
    "                # The label with the highest value will be our prediction\n",
    "                _, predicted = torch.max(predicted_outputs, 1)\n",
    "                running_vall_loss += val_loss.item()\n",
    "                total += outputs.size(0)\n",
    "                running_accuracy += (predicted == outputs).sum().item()\n",
    "\n",
    "                # Calculate validation loss value\n",
    "        val_loss_value = running_vall_loss/len(validate_loader)\n",
    "\n",
    "        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.\n",
    "        accuracy = (100 * running_accuracy / total)\n",
    "\n",
    "        # Save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "            # Print the statistics of the epoch\n",
    "        print('Completed training batch', epoch,\n",
    "              'Training Loss is: %.4f' %train_loss_value,\n",
    "              'Validation Loss is: %.4f' %val_loss_value,\n",
    "              'Accuracy is %d %%' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1721f",
   "metadata": {},
   "source": [
    "Define function to test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # Load the model that we saved at the end of the training loop\n",
    "    model = Network(input_size, output_size)\n",
    "    path = \"NetModel.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    running_accuracy = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, outputs = data\n",
    "            outputs = outputs.to(torch.float32)\n",
    "            predicted_outputs = model(inputs)\n",
    "            _, predicted = torch.max(predicted_outputs, 1)\n",
    "            total += outputs.size(0)\n",
    "            running_accuracy += (predicted == outputs).sum().item()\n",
    "\n",
    "        print('Accuracy of the model based on the test set of',\n",
    "              test_split,\n",
    "              'inputs is: %d %%' % (100 * running_accuracy / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a040cc",
   "metadata": {},
   "source": [
    "Optional: Define function to test which species were easier to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96337f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_species():\n",
    "    # Load the model that we saved at the end of the training loop\n",
    "    model = Network(input_size, output_size)\n",
    "    path = \"NetModel.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    labels_length = len(labels) # how many labels of Irises we have. = 3 in our database.\n",
    "    labels_correct = list(0. for i in range(labels_length)) # list to calculate correct labels [how many correct setosa, how many correct versicolor, how many correct virginica]\n",
    "    labels_total = list(0. for i in range(labels_length))   # list to keep the total # of labels per type [total setosa, total versicolor, total virginica]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, outputs = data\n",
    "            predicted_outputs = model(inputs)\n",
    "            _, predicted = torch.max(predicted_outputs, 1)\n",
    "\n",
    "            label_correct_running = (predicted == outputs).squeeze()\n",
    "            label = outputs[0]\n",
    "            if label_correct_running.item():\n",
    "                labels_correct[label] += 1\n",
    "            labels_total[label] += 1\n",
    "\n",
    "    label_list = list(labels.keys())\n",
    "    for i in range(output_size):\n",
    "        print('Accuracy to predict %5s : %2d %%' % (label_list[i], 100 * labels_correct[i] / labels_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc94e0e5",
   "metadata": {},
   "source": [
    "Define function to convert to ONNX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert():\n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "\n",
    "    # model input tensor\n",
    "    model_input = torch.randn(1, 4, requires_grad=True)\n",
    "\n",
    "    # Export the model\n",
    "    torch.onnx.export(model,                    # model being run\n",
    "                      model_input,              # model input (or a tuple for multiple inputs)\n",
    "                      \"models/Network.onnx\",    # where to save the model\n",
    "                      export_params=True,       # store the trained parameter weights inside the model file\n",
    "                      opset_version=12,         # the ONNX version to export the model to\n",
    "                      do_constant_folding=True, # whether to execute constant folding for optimization\n",
    "                      input_names =['input'],   # the model's input names\n",
    "                      output_names=['output'],  # the model's output names\n",
    "                      dynamic_axes={'input' : {0: 'input'},    # variable length axes\n",
    "                                    'output': {0: 'output'}})\n",
    "    \n",
    "    print('\\nModel has been converted to ONNX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c6db14",
   "metadata": {},
   "source": [
    "Run training and export the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_epochs = 10\n",
    "    train(num_epochs)\n",
    "    print('Finished Training\\n')\n",
    "    saveModel()\n",
    "    test()\n",
    "    test_species()\n",
    "    convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0713f",
   "metadata": {},
   "source": [
    "Now find the model in `models/Network.onnx`!\n",
    "\n",
    "Use APIs to inspect the model\n",
    "(also see [vespa-analyze-onnx-model](https://docs.vespa.ai/en/onnx.html#using-vespa-analyze-onnx-model)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27662823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "onnx_model = onnx.load(\"models/Network.onnx\")\n",
    "onnx.checker.check_model(onnx_model, full_check=True)\n",
    "\n",
    "session = onnxruntime.InferenceSession(\"models/Network.onnx\", providers=['CPUExecutionProvider'])\n",
    "\n",
    "print(\"Inputs:\")\n",
    "for model_input in session.get_inputs():\n",
    "    print(\"name:  \" + model_input.name)\n",
    "    print(\"type:  \" + model_input.type)\n",
    "    print(\"shape: \", end=\"\")\n",
    "    print(model_input.shape)\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "for model_output in session.get_outputs():\n",
    "    print(\"name:  \" + model_output.name)\n",
    "    print(\"type:  \" + model_output.type)\n",
    "    print(\"shape: \", end=\"\")\n",
    "    print(model_output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
