<!-- Copyright Vespa.ai. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root. -->

<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://assets.vespa.ai/logos/Vespa-logo-green-RGB.svg">
  <source media="(prefers-color-scheme: light)" srcset="https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg">
  <img alt="#Vespa" width="200" src="https://assets.vespa.ai/logos/Vespa-logo-dark-RGB.svg" style="margin-bottom: 25px;">
</picture>


# Vespa Sample Applications
The [Vespa](https://vespa.ai/) sample applications are created to run both self-hosted and on Vespa Cloud.
You can easily deploy the sample applications to Vespa Cloud without changing the files -
just follow the same steps as for
[![logo](/assets/vespa-logomark-tiny.png) Managed Vector Search using Vespa Cloud](https://github.com/vespa-cloud/vector-search),
adding security credentials.

First-time users should go through the [getting-started](https://docs.vespa.ai/en/getting-started.html) guides first.

Explore the [examples](examples) for smaller applications helping you getting started with a particular feature,
and see [operations](examples/operations) for operational examples.

## Standard structure of a Sample Application

We try to build each sample application with a standard structure, so you can
 easily find your way around. This section gives you an overview of this structure.

<details>
<summary>Click to expand</summary>

The standard structure is as follows:

```plaintext
one-sample-app/
‚îú‚îÄ README.md
‚îú‚îÄ dataset/
‚îÇ  ‚îú‚îÄ a-document.json
‚îÇ  ‚îú‚îÄ another-doc.json
‚îÇ  ‚îú‚îÄ ...
‚îú‚îÄ app/
‚îÇ  ‚îú‚îÄ security/
‚îÇ  ‚îú‚îÄ schemas/
‚îÇ  ‚îÇ  ‚îú‚îÄ my_vespa_schema.sd
‚îÇ  ‚îú‚îÄ services.xml
‚îÇ  ‚îú‚îÄ ...
‚îú‚îÄ script/
‚îÇ  ‚îú‚îÄ build.sh             # when required
‚îÇ  ‚îú‚îÄ ...
```

There might be other files and folders than the ones listed here, but this should be the bare minimum that you can expect.

Let's analyze the structure:

- `README.md` - self explainatory: the README specific for the sample application, we recommend reading it through.
- `dataset/` - contains the dataset used for the sample application. This is usually a small set of documents, but it can be larger.

  **Note:** Sometimes this might be missing, and will be generated by the build script (see below), this is usually because the dataset is too large to be included in the repository.
-  `app/` - contains the [Vespa application package](https://docs.vespa.ai/en/application-packages.html), this is the actual definition of the Vespa deployment. The bare minimum includes:
    - `security/` - this is where you will place your `clients.pem` certificate for data-plane authentication. _(Refer to our [Security Guide](https://cloud.vespa.ai/en/security/guide.html#application-configuration))_
    - `schemas/` - contains [the schema](https://docs.vespa.ai/en/schemas.html) files used for the application. This is usually a single file, but it can be multiple files.
    - `services.xml` - contains the services configuration for the application. This is usually a single file.
    - Other files and folders that are required for the application to run.
- `script/` - contains the optional scripts used to help building the application package. This is usually a single file, but it can be multiple files.
  - `build.sh` - this is the main script, if multiple files are present, this will be the only one you'll need to worry about.

    **Note:** We recomend refering to the README for the sample application for details on how to run it.


> [!NOTE]
> We are in the process of updating the sample applications to follow the
> structure described here, but some applications may not be fully updated
> yet, so please check the README files in each application for details.

</details>


## Getting Started
[![logo](/assets/vespa-logomark-tiny.png) Album Recommendations](album-recommendation/) is the intro application to Vespa.
Learn how to configure the schema for simple recommendation and search use cases.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Hybrid Search - Quickstart](https://pyvespa.readthedocs.io/en/latest/getting-started-pyvespa.html) and
[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Hybrid Search - Quickstart on Vespa Cloud](https://pyvespa.readthedocs.io/en/latest/getting-started-pyvespa-cloud.html)
create a hybrid text search application combining traditional keyword matching with semantic vector search (dense retrieval).
They also demonstrate the Vespa native embedder functionality.
These are intro-level applications for Python users using more advanced Vespa features.
Use [![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Authenticating to Vespa Cloud](https://pyvespa.readthedocs.io/en/latest/authenticating-to-vespa-cloud.html) for Vespa Cloud credentials.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Querying Vespa](https://pyvespa.readthedocs.io/en/latest/query.html)
is a good start for Python users, exploring how to query Vespa using the Vespa Query Language (YQL).

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Read and write operations](https://pyvespa.readthedocs.io/en/latest/reads-writes.html)
documents ways to feed, get, update, and delete data;
Using context manager for efficiently managing resources and feeding streams of data using `feed_iter`,
which can feed from streams, Iterables, Lists, and files by the use of generators.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Application packages](https://pyvespa.readthedocs.io/en/latest/application-packages.html)
is a good intro to the concept of application packages in Vespa.
Try [![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Advanced Configuration](https://pyvespa.readthedocs.io/en/latest/advanced-configuration.html) for Vespa Services configuration.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Examples](https://pyvespa.readthedocs.io/en/latest/examples/pyvespa-examples.html)
is a repository of small snippets and examples, e.g., really simple vector distance search applications.

The [![logo](/assets/vespa-logomark-tiny.png) News and Recommendation Tutorial](news/)
demonstrates basic search functionality and is a great place to start exploring Vespa features.
It creates a recommendation system where the approximate nearest neighbor search in a shared user/item embedding space
is used to retrieve recommended content for a user.
This app also demonstrates using [parent-child](https://docs.vespa.ai/en/parent-child.html) relationships.

The [![logo](/assets/vespa-logomark-tiny.png) Text Search Tutorial](text-search)
demonstrates traditional text search using
[BM25](https://docs.vespa.ai/en/reference/bm25.html)/[Vespa nativeRank](https://docs.vespa.ai/en/nativerank.html),
and is a good start to using the [MS Marco](https://huggingface.co/datasets/microsoft/ms_marco) dataset.



## Vector Search, Hybrid Search and Embeddings
There is a growing interest in AI-powered vector representations of unstructured multimodal data
and searching efficiently over these representations.
[![logo](/assets/vespa-logomark-tiny.png) Managed Vector Search using Vespa Cloud](https://github.com/vespa-cloud/vector-search)
describes how to unlock the full potential of multimodal AI-powered vector representations using Vespa Cloud.

[![logo](/assets/vespa-logomark-tiny.png) Vespa Multi-Vector Indexing with HNSW](multi-vector-indexing/) and
[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Multi-vector indexing with HNSW](https://pyvespa.readthedocs.io/en/latest/examples/multi-vector-indexing.html)
demonstrate how to index multiple vectors per document field for semantic search for longer documents.
These are more advanced than the Hybrid Search examples in the Getting Started section.

[![logo](/assets/vespa-logomark-tiny.png) Vector Streaming Search](vector-streaming-search)
uses vector streaming search for naturally partitioned data, see the
[blog post](https://blog.vespa.ai/announcing-vector-streaming-search/) for details.

[![logo](/assets/vespa-logomark-tiny.png) Multilingual Search with multilingual embeddings](multilingual-search)
demonstrates multilingual semantic search with multilingual text embedding models.

[![logo](/assets/vespa-logomark-tiny.png) Simple hybrid search with SPLADE](splade)
uses the Vespa [splade-embedder](https://docs.vespa.ai/en/embedding.html#splade-embedder) for
semantic search using sparse vector representations,
and is a good intro to SPLADE and sparse learned weights for ranking.

[![logo](/assets/vespa-logomark-tiny.png) Customizing Frozen Data Embeddings in Vespa](custom-embeddings)
demonstrates how to adapt frozen embeddings from foundational embedding models -
see the [blog post](https://blog.vespa.ai/tailoring-frozen-embeddings-with-vespa/).
Frozen data embeddings from foundational models is an emerging industry practice
for reducing the complexity of maintaining and versioning embeddings.
The frozen data embeddings are re-used for various tasks, such as classification, search, or recommendations.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Using Cohere Binary Embeddings in Vespa](https://pyvespa.readthedocs.io/en/latest/examples/cohere-binary-vectors-in-vespa-cloud.html)
demonstrates how to use the Cohere binary vectors with Vespa,
including a re-ranking phase that uses the float query vector version for improved accuracy.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Billion-scale vector search with Cohere binary embeddings in Vespa](https://pyvespa.readthedocs.io/en/latest/examples/billion-scale-vector-search-with-cohere-embeddings-cloud.html)
uses the [Cohere int8 & binary Embeddings](https://cohere.com/blog/int8-binary-embeddings)
with a coarse-to-fine search and re-ranking pipeline;
This reduces costs but offers the same retrieval (nDCG) accuracy.
The packed binary vector representation is stored in memory,
with an optional [HNSW index](https://docs.vespa.ai/en/approximate-nn-hnsw.html) using
[hamming](https://docs.vespa.ai/en/reference/schema-reference.html#hamming) distance.
The `int8` vector representation is stored on disk
using Vespa‚Äôs [paged](https://docs.vespa.ai/en/attributes.html#paged-attributes) option.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Multilingual Hybrid Search with Cohere binary embeddings and Vespa](https://pyvespa.readthedocs.io/en/latest/examples/multilingual-multi-vector-reps-with-cohere-cloud.html)
demonstrates:
* Building a multilingual search application over a sample of the German split of Wikipedia using
  [binarized Cohere embeddings](https://huggingface.co/datasets/Cohere/wikipedia-2023-11-embed-multilingual-v3-int8-binary).
* Indexing multiple binary embeddings per document without having to split the chunks across multiple retrievable units.
* Hybrid search, combining the lexical matching capabilities of Vespa with Cohere binary embeddings.
* Re-scoring the binarized vectors for improved accuracy.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: BGE-M3 - The Mother of all embedding models](https://pyvespa.readthedocs.io/en/latest/examples/mother-of-all-embedding-models-cloud.html)
demonstrates how to use the [BGE-M3](https://github.com/FlagOpen/FlagEmbedding/blob/master/research/BGE_M3/BGE_M3.pdf) embeddings
and represent all three embedding representations in Vespa.
This code is inspired by the [BAAI/bge-m3 README](https://huggingface.co/BAAI/bge-m3).

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Evaluating retrieval with Snowflake arctic embed](https://pyvespa.readthedocs.io/en/latest/examples/evaluating-with-snowflake-arctic-embed.html)
shows how different rank profiles in Vespa can be set up and evaluated.
For the rank profiles that use semantic search,
we will use the small version of [Snowflake‚Äôs arctic embed model series](https://huggingface.co/Snowflake/snowflake-arctic-embed-s) for generating embeddings.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Exploring the potential of OpenAI Matryoshka ü™Ü embeddings with Vespa](https://pyvespa.readthedocs.io/en/latest/examples/Matryoshka_embeddings_in_Vespa-cloud.html)
demonstrates the effectiveness of using the recently released (as of January 2024) OpenAI `text-embedding-3` embeddings with Vespa.
Specifically, we are interested in the [Matryoshka Representation Learning](https://aniketrege.github.io/blog/2024/mrl/) technique used in training,
which lets us _"shorten embeddings (i.e., remove some numbers from the end of the sequence) without the embedding losing its concept-representing properties"_.
This allows us to trade off a small amount of accuracy in exchange for much smaller embedding sizes,
so we can store more documents and search them faster.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Using Mixedbread.ai embedding model with support for binary vectors](https://pyvespa.readthedocs.io/en/latest/examples/mixedbread-binary-embeddings-with-sentence-transformers-cloud.html)
shows how to use the [mixedbread-ai/mxbai-embed-large-v1](https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1) model
with support for binary vectors with Vespa.
The notebook example also includes a re-ranking phase that uses the float query vector version for improved accuracy.
The re-ranking step makes the model perform at 96.45% of the full float version,
with a 32x decrease in storage footprint.



## Retrieval Augmented Generation (RAG) and Generative AI
[![logo](/assets/vespa-logomark-tiny.png) Retrieval Augmented Generation (RAG) in Vespa](retrieval-augmented-generation)
is an end-to-end RAG application where all the steps are run within Vespa.
This application focuses on the generation part of RAG,
with a simple text search using [BM25](https://docs.vespa.ai/en/reference/bm25.html).
This application has three versions of an end-to-end RAG application:

* Using an external LLM service to generate the final response.
* Using local LLM inference to generate the final response.
* Deploying to Vespa Cloud and using GPU-accelerated LLM inference to generate the final response.
  This includes using Vespa Cloud's [Secret Store](https://cloud.vespa.ai/en/security/secret-store.html#secret-management)
  to save the OpenAI API key.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Building cost-efficient retrieval-augmented personal AI assistants](https://pyvespa.readthedocs.io/en/latest/examples/scaling-personal-ai-assistants-with-streaming-mode-cloud.html)
uses [streaming mode](https://docs.vespa.ai/en/streaming-search.html)
for cost-efficient retrieval for applications that store and retrieve personal data.
This notebook connects a custom [LlamaIndex Retriever](https://docs.llamaindex.ai/)
with a Vespa app using streaming mode to retrieve personal data.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Turbocharge RAG with LangChain and Vespa Streaming Mode for Partitioned Data](https://pyvespa.readthedocs.io/en/latest/examples/turbocharge-rag-with-langchain-and-vespa-streaming-mode-cloud.html)
uses [streaming mode](https://docs.vespa.ai/en/streaming-search.html)
to build cost-efficient RAG applications over naturally sharded data - also available as a blog post:
[Turbocharge RAG with LangChain and Vespa Streaming Mode for Sharded Data](https://blog.vespa.ai/turbocharge-rag-with-langchain-and-vespa-streaming-mode/).
This example features using [elementSimilarity](https://docs.vespa.ai/en/reference/rank-features.html#elementSimilarity(name))
in search results to easily inspect each chunk's closeness to the query embedding.

Also try [![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Chat with your pdfs with ColBERT, LangChain, and Vespa](https://pyvespa.readthedocs.io/en/latest/examples/chat_with_your_pdfs_using_colbert_langchain_and_Vespa-cloud.html) -
this demonstrates how you can now use ColBERT ranking natively in Vespa,
which handles the ColBERT embedding process with no custom code.



## Visual Search
[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Visual PDF RAG with Vespa - ColPali demo application](https://pyvespa.readthedocs.io/en/latest/examples/visual_pdf_rag_with_vespa_colpali_cloud.html)
is an end-to-end demo application for visual retrieval of PDF pages, including a frontend web application -
try [vespa-engine-colpali-vespa-visual-retrieval.hf.space](https://vespa-engine-colpali-vespa-visual-retrieval.hf.space/) for a live demo.
The main goal of the demo is to make it easy to create your own PDF Enterprise Search application using Vespa!

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Vespa ü§ù ColPali: Efficient Document Retrieval with Vision Language Models](https://pyvespa.readthedocs.io/en/latest/examples/colpali-document-retrieval-vision-language-models-cloud.html)
demonstrates how to retrieve PDF pages using the embeddings generated by the [ColPali](https://huggingface.co/vidore/colpali) model.
ColPali is a powerful Vision Language Model (VLM) that can generate embeddings for images and text.
This notebook uses ColPali to generate embeddings for images of PDF _pages_ and store them in Vespa.
We also store the base64-encoded image of the PDF page and some metadata like _title_ and _url_.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Scaling ColPALI (VLM) Retrieval](https://pyvespa.readthedocs.io/en/latest/examples/simplified-retrieval-with-colpali-vlm_Vespa-cloud.html)
demonstrates how to represent [ColPali](https://huggingface.co/vidore/colpali) in Vespa and to scale to large collections.
Also see the [Scaling ColPali to billions of PDFs with Vespa](https://blog.vespa.ai/scaling-colpali-to-billions/) blog post.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: ColPali Ranking Experiments on DocVQA](https://pyvespa.readthedocs.io/en/latest/examples/colpali-benchmark-vqa-vlm_Vespa-cloud.html)
shows how to reproduce the ColPali results on [DocVQA](https://huggingface.co/datasets/vidore/docvqa_test_subsampled) with Vespa.
The dataset consists of PDF documents with questions and answers.
We demonstrate how we can binarize the patch embeddings
and replace the float [MaxSim](https://blog.vespa.ai/scaling-colpali-to-billions/) scoring
with a [hamming](https://docs.vespa.ai/en/reference/schema-reference.html#hamming)-based MaxSim
without much loss in ranking accuracy but with a significant speedup (close to 4x) and reducing the memory (and storage) requirements by 32x.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: PDF-Retrieval using ColQWen2 (ColPali) with Vespa](https://pyvespa.readthedocs.io/en/latest/examples/pdf-retrieval-with-ColQwen2-vlm_Vespa-cloud.html)
is a continuation of the notebooks related to the ColPali models (above) for complex document retrieval,
and demonstrates use of the [ColQWen2](https://huggingface.co/vidore/colqwen2-v0.1) model checkpoint.

[![logo](/assets/vespa-logomark-tiny.png) Billion-Scale Image Search](billion-scale-image-search/)
demonstrates billion-scale image search using a [CLIP](https://github.com/openai/CLIP) model
exported in [ONNX](https://onnx.ai/)-format for retrieval.
It features separation of compute from storage and query-time vector similarity de-duping.
It uses PCA to reduce from 768 to 128 dimensions.



## Video Search
[![logo](/assets/vespa-logomark-tiny.png) Text-video search](text-video-search/) is a notebook that
downloads a set of videos, converts from `.avi` to `.mp4`, creates CLIP embeddings,
feeds to Vespa and lets you query the videos in text using a Streamlit application.
It is a good start for creating a video search application using Vespa!

[![logo](/assets/vespa-logomark-tiny.png) Video Search and Retrieval with Vespa and TwelveLabs](https://github.com/vespa-engine/pyvespa/blob/master/docs/sphinx/source/examples/video_search_twelvelabs_cloud.ipynb) is a notebook
showcasing the use of [TwelveLabs](https://www.twelvelabs.io/) state-of-the-art generation and embedding models
for video processing. It demonstrates how to generate rich metadata (including summaries and keywords) for videos
using TwelveLabs' technology, and how to embed video chunks for efficient retrieval. The notebook processes three
sample videos, segments them into chunks, and stores their embeddings along with metadata in Vespa's multi-vector
tensors. You can perform hybrid searches to find specific video scenes based on natural language descriptions.
This serves as an excellent starting point for implementing advanced video retrieval with Vespa!

## Ranking
[![logo](/assets/vespa-logomark-tiny.png) MS Marco Passage Ranking](msmarco-ranking/)
shows how to represent state-of-the-art text ranking using Transformer (BERT) models.
It uses the MS Marco passage ranking datasets and features
bi-encoders, cross-encoders, and late-interaction models (ColBERT):
- Simple single-stage sparse retrieval accelerated by the
  [WAND](https://docs.vespa.ai/en/using-wand-with-vespa.html)
  dynamic pruning algorithm with [BM25](https://docs.vespa.ai/en/reference/bm25.html) ranking.
- Dense (vector) search retrieval for efficient candidate retrieval
  using Vespa's support for [approximate nearest neighbor search](https://docs.vespa.ai/en/approximate-nn-hnsw.html).
- Re-ranking using the [Late contextual interaction over BERT (ColBERT)](https://arxiv.org/abs/2004.12832) model.
- Re-ranking using a *cross-encoder* with cross attention between the query and document terms.
- [Multiphase retrieval and ranking](https://docs.vespa.ai/en/phased-ranking.html)
  combining efficient retrieval (WAND or ANN) with re-ranking stages.
- Using Vespa [embedder](https://docs.vespa.ai/en/embedding.html) functionality.
- Hybrid ranking.

With Vespa‚Äôs phased ranking capabilities,
doing cross-encoder inference for a subset of documents at a later stage in the ranking pipeline
can be a good trade-off between ranking performance and latency.
[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Using Mixedbread.ai cross-encoder for reranking in Vespa.ai](https://pyvespa.readthedocs.io/en/latest/examples/cross-encoders-for-global-reranking.html)
shows how to use the [Mixedbread.ai](https://www.mixedbread.ai/)
cross-encoder for [global-phase reranking](https://docs.vespa.ai/en/reference/schema-reference.html#using-a-global-phase-expression) in Vespa.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Standalone ColBERT with Vespa for end-to-end retrieval and ranking](https://pyvespa.readthedocs.io/en/latest/examples/colbert_standalone_Vespa-cloud.html)
illustrates using the [colbert-ai package](https://github.com/stanford-futuredata/ColBERT) to produce token vectors,
instead of using the native Vespa [ColBERT embedder](https://docs.vespa.ai/en/embedding.html#colbert-embedder).
The guide illustrates how to feed and query using a single passage representation:
* Compress token vectors using binarization compatible with Vespa's `unpack_bits` used in ranking.
  This implements the binarization of token-level vectors using `numpy`.
* Use Vespa [hex feed format](https://docs.vespa.ai/en/reference/document-json-format.html#tensor) for binary vectors.
* Query examples.

As a bonus, this also demonstrates how to use ColBERT end-to-end with Vespa for both retrieval and ranking.
The retrieval step searches the binary token-level representations using hamming distance.
This uses 32 nearestNeighbor operators in the same query, each finding 100 nearest hits in hamming space.
Then, the results are re-ranked using the full-blown MaxSim calculation.

ColBERT token-level embeddings:
* [![logo](/assets/vespa-logomark-tiny.png) Simple hybrid search with ColBERT](colbert)
  uses a single vector embedding model for retrieval and ColBERT (multi-token vector representation) for re-ranking.
  This semantic search application demonstrates the [colbert-embedder](https://docs.vespa.ai/en/embedding.html#colbert-embedder)
  and the tensor expressions for [ColBERT MaxSim](https://docs.vespa.ai/playground/#N4KABGBEBmkFxgNrgmUrWQPYAd5QGNIAaFDSPBdDTAF30gGJGwA1AUwGccBDMAYSwAbAEIBRAEoAVMAFkeADwDKASwC2YKewB2nLACcwYhTn1dOKrNrAAFITwCeAc31YArtoAmAHW2+pABYqnGA49s6uHp5g7Ao8amHsYE5uKp5cYFHs+py0PF4q2k5gWNBgtAFJHNx8tDp6hrGm5pa65QE8tGDqiWo6XRVJ8srqYBZqKvb6KrQOmZzs0YUCwuLSAHRgAOpJ6WpWufqdSYPd2nX6fZ4qx2N1OJy+hQBuws+LZ+1JBDxCBG72WitTibXy+JTsJK-PRfJAEYQAI2ytAAtOw1EjPOl9ABdAAUAVotAecAA9KTPFgCCD3jV1jwVKSdEyMYtrkV1oS1EJGPChEj9Kj0ZjsQBKMD5aKIPkCrqceKJCU4MIqH5Aqz4wnEzhk0lOGYBNwI9bwtSk2m8NFFQrsUnyhJCdgonjKzik2hmW1qHi5bKkmXI0WgvzaACE0sRyLA3oU401RJJ5KOAHd1vqKka3At9PDzv0TVgzbl8tADJ4UdA3LQ3GZPJ0eKTBKJJFJSd7ChSqW71DwnFx-ZHBaVoKqbkJ1jgiqKwdodmAOu9ysmsNGVAoPnVdAYQhVOmAzM0FudYU21jJ3gRaAZ9+xD-1OsCSmUAI5ubJzC9XnJgPEAKl-r7vniz60KK-7ipKYCUv8fTHp+24-v+nQeioCJVuweIBoKYG-tOIaBOwcwIlgFTzjwi6nPaSSFOk67RHi6S6Ow4rXLBFhWGA2jxEk-4KP+xASl4YDJkkWYnMuUHqPUj6loYCJmM8MwOMGvgomAAAGm4NMBtDAAAvgJCiIAATDiorqbCWFdIB+hzFp16zDg7CqRp9n6AxukGWARmmeZlmDl00FuLBAz1A5DhOWAM7GGE+QPhxsmwlxVzlGFhisdJBxRdoakAbQv4Sgi8nsIp8XWIlNl2dkGgub+nj5YVxWleq5UOZUUFUsF-SpZc2W5XxsI0bEHwMfUzGSWxrTCQaS4rhlujAjOABi175GcHpYJ4biXlNV5sFwvCpVuOQzi5iBaMd62uFtO0cSkaTsPG2q6tBNIHTw9KMsybkomJ+govd6ScrQ3J4Wp51paE0wTECi6Vtot26E9iadtS6wWh9DJMtopJmNA2Q6AQtpHNoADWhROGiJhmJw7G6MD3KMKY6gzCo7wVh4iOcGDSAXQ0nFWCizMw2zSTw1zyM6uSr3o+9n3Y7j7D42YCPE-k5NFFTh50yCXI8togvC6z7Piy13NnSIQhYE4CCCAkVYU9NpFuSEyzVLwku6giVtOLLdJY6aOAO5ryYGiiLuknh-jtaWQhW6HRRQUrNo7u1VlgJVgnREFIVHQ0IKQGQqB6UXBlF9Q5C4Aw7AkEXEAUPgFc0JA2gMJVOmirXNCYDXCCQG5AA80BW50AB8On6YZJlmXAwBgAADAgiDz8QACMOICavcCIKvxCmQJADM28ACzEAArDiemF93JcYGXGBN-XVd9zXpDdw3VB15grd98h0xoXUTCAVO5v27lAXuUBB7DywGPDyk9vLT1FLPReiAD7EGPhvMAW9EBn2IAANkwcZbeAB2YgAAOS+18aC32LqAiAj8oDP0IF3ZulA0Bf3rvQPuzAWA2GyLJCYidKTEmuttWgIQsDvEMJRDotYJqZWsAoZaKgchdBEknfYugPS3CaDTCwidTjCKhptMRIQkS0BEjoCUcdYSZwuBoeC35IK-CELCHO3V7FgEcSCbK0ckhG1hkkA8NN7wtSfLCWO8dHa6JaBxYIGl1LqVrNtDC7cQLigKn-VC6EgH8kDAJTgwVDLmUSTOQI8SYm0ymjTAE4jPh8G0OwZMedrylFhI5JImk0pwIMiBfSflQ7O3akY0wJjLxjHhDTMA5jLHWBcbYt8tkvHsEvAhZxNj3FwRWV+AuX8aEQHvqgBh2A2GQFfl-D+7CwFQB-lAYRoybriJYe-CBkBClqDxBnRZDgO5gEyUSf+OSrKimKVQu+pc6FXObkwyARBIX1zYQwzhDAeFgCWjRR2pwYwTIMGLVaNi7HVRCB3GcWwZrzMMSRB5piwA-D+ACY4ngBLqOTPkAYK4RxCSxYoHF0whGdVzo4gpK51HJKJiUKRsJ-z1X-PIhaVhfBZkdupGMFkfSwl7C4dgThOjXlNq0dYYLi4QvLhcmF5z36Io4TchgYr2AAH0YzPObq8u1DEqWiMvJwASMYBL1U7nsk1D8zWnLhRcq11z+4ouYGAJQwVwnYs4JMjIiV5mEsuI8bQBEwCct+HcW8mw5wLjxVEWEibJmO02aFXqSbcWhGyF898PU1CbGzbm1xvocDdB3Cud5XwFjlBXFgBEeRlinFPC2OQihVAaFrWYQ1ga76QuOea51CLG7Wpbgwd59rSj2pAmunu27gp4jtY6xQAab5BqOSGhgYbLUbsjVwqAMabA8COC4F0AQwCOneK44YM7fATukN26ZPoPgcT4ITTaDapAk04AIht+x0iuMGd+vgQgWZ1GiLmOoCg5TsEAqrH9OgnCkTxGfVexkQVjBXHtYJXBupWyKA23DsRxECSsEkRpiwe31v0AI2lhoyYU3WGUlcDGjxdF4B+o4OAAjeuEtRc4nqoScSadGF0Tls5SXldYX8OACocUpTBbqknQmtDgDORJXTjp4hwPA+q8CfJmRs6SmaFiVzemVBuNKin1E-GsAbLozG+yGDErCTgAQDChUugIvcYkljWFODwYii5YgKkdD4ttwgokGMhukTlrMOIdFTkkKiXjfhvhCIlGTvY5PfvnhKMrMQ4gOihGl9gAlBjWHUTwLEgkSKVEMHVz98mF1XqXaa9+q74VQAjWArdv8AXZMAVZe1o2Gvc0PfXV5UCR60HHg5ryTmvIuaQWgXwwAcBwBXlBWgt3DK3b0nANBV2bt3fqo97ycBV4vdPu977X3d4-fni93BgPPsPZBwoX7L28HEEh36h7xkntg7gKQpH924Co5+39uAZDEchmu795H33Yfo5XoDkHX27uw-x7vanZOYfPbgAATiJyTmn0OnsM8Z9oLnZPccU5e6jpn2Phdw4J74K+i7aHTehaGw9lykWQOjSweQ2g5gjM9XUspMdctYATsUJyAmDBqBazrsZXQ6X-EBFNRKMj30fHmnTP5v4+K-hUlmoIIQalCDqcsPgB8USu9aHm7z2mWmGDaacDprlunHeR8AGjfS9IDPJTYyl0nde8pTfi1xm2v2KbTd85tIR1muKreXib1Dr30NvS-ZXC3363MgPsMw9r7m684Dt8Bx6PmNtsr8-5KEAEYXW0X+T3NiAKEvXXqbwaZtK7myrzdz6mAxokIsFJJRTdlX11Y0VO-xUIjsu1ctBhK0Co8dVfjQ+qq9Ugqb0I776tfqNQc+vULK6nItawx9RbNvM9eqPvM5W1E-DCDvB1bva3RTX1e7efcFRfG9ZfO9ZvQA9+DfVFONDQPaTlaICldqADUYOdDIF-KfAIaOeJW3BlOoFrPtWPdqdNC3VtX3UDHrWEEg2dZNHNa8EqJtSg2vZA+XJfRXauDAz+SNYAyA-degObXbCAm6DCEA2gApIpDOUCT-MAfZHQ5dRvZhVfFvZuDfAiXrb4NaczY8EzLqY8X9dgDtXg9VblBQdQeNJg-xN-Mbb9Mg3ZSbUQ1A8QpvIwzA5uNvGMGwMA11SA09WQkCH1RQASHAJA41EQnEEAPSIAA).
  It also features [reciprocal rank fusion](https://docs.vespa.ai/en/phased-ranking.html#cross-hit-normalization-including-reciprocal-rank-fusion)
  to fuse different rankings.
* [![logo](/assets/vespa-logomark-tiny.png) Long-Context ColBERT](colbert-long)
  demonstrates Long-Context ColBERT (multi-token vector representation) with extended context windows for long-document retrieval,
  as announced in [Vespa Long-Context ColBERT](https://blog.vespa.ai/announcing-long-context-colbert-in-vespa/).
  The app demonstrates the [colbert-embedder](https://docs.vespa.ai/en/embedding.html#colbert-embedder)
  and the tensor expressions for performing two types of extended ColBERT late-interaction for long-context retrieval.
  This app uses [trec-eval](https://github.com/usnistgov/trec_eval) for evaluation using
  [nDCG](https://en.wikipedia.org/wiki/Discounted_cumulative_gain).
* [![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Standalone ColBERT + Vespa for long-context ranking](https://pyvespa.readthedocs.io/en/latest/examples/colbert_standalone_long_context_Vespa-cloud.html)
  is a guide on how to use the [ColBERT](https://github.com/stanford-futuredata/ColBERT) package to produce token-level vectors,
  as an alternative to using the native Vespa [ColBERT embedder](https://docs.vespa.ai/en/embedding.html#colbert-embedder).
  It illustrates how to feed multiple passages per Vespa document (long-context):
  * Compress token vectors using binarization that is compatible with Vespa's `unpack_bits`.
  * Use Vespa hex feed format for binary vectors with mixed vespa tensors.
  * How to query Vespa with the ColBERT query tensor representation.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: LightGBM: Training the model with Vespa features](https://pyvespa.readthedocs.io/en/latest/examples/lightgbm-with-categorical.html)
deploys and uses a LightGBM model in a Vespa application.
The tutorial runs through how to:
1. Train a LightGBM classification model with variable names supported by Vespa.
2. Create Vespa application package files and export them to an application folder.
3. Export the trained LightGBM model to the Vespa application folder.
4. Deploy the Vespa application using the application folder.
5. Feed data to the Vespa application.
6. Assert that the LightGBM predictions from the deployed model are correct.

[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: LightGBM: Mapping model features to Vespa features](https://pyvespa.readthedocs.io/en/latest/examples/lightgbm-with-categorical-mapping.html)
shows how to deploy a LightGBM model with feature names that do not match Vespa feature names.
In addition to the steps in the app above, this tutorial:
1. Trains a LightGBM classification model with generic feature names that will not be available in the Vespa application.
2. Creates an application package and includes a mapping from Vespa feature names to LightGBM model feature names.



## Performance
[![logo](/assets/vespa-logomark-tiny.png) Pyvespa: Feeding performance](https://pyvespa.readthedocs.io/en/latest/examples/feed_performance.html)
intends to shine some light on the different modes of feeding documents to Vespa, looking at 4 different methods:
* Using `VespaSync`
* Using `VespaAsync`
* Using `feed_iterable()`
* Using [Vespa CLI](https://docs.vespa.ai/en/vespa-cli)

Use [![logo](/assets/vespa-logomark-tiny.png) Feeding to Vespa Cloud](https://pyvespa.readthedocs.io/en/latest/examples/feed_performance_cloud.html)
to test feeding using [Vespa Cloud](https://vespa.ai/free-trial/).



## E-Commerce
The [![logo](/assets/vespa-logomark-tiny.png) e-commerce](use-case-shopping/) application is an end-to-end shopping engine,
using the [Amazon product data set](http://jmcauley.ucsd.edu/data/amazon/links.html).
This use case bundles a front-end application.
It demonstrates building next-generation E-commerce Search using Vespa,
and is a good intro to using the Vespa Cloud [CI/CD tests](https://cloud.vespa.ai/en/automated-deployments#system-tests).

Data in e-commerce applications is structured,
so [Gradient Boosted Decision Trees (GBDT)](https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting)
models are popular in this domain.
Try [![logo](/assets/vespa-logomark-tiny.png) Vespa Product Ranking](commerce-product-ranking/) for using
learning-to-rank (LTR) techniques (using [XGBoost](https://xgboost.readthedocs.io/) and [LightGBM](https://lightgbm.readthedocs.io/))
for improving product search ranking.

In Vespa, faceting (the attribute filtering) is called [grouping](https://docs.vespa.ai/en/grouping.html).
[![logo](/assets/vespa-logomark-tiny.png) Grouping Results](examples/part-purchases-demo)
is a quick intro to implementing faceting/grouping in Vespa.

Recommendations are integral to e-commerce applications.
The [![logo](/assets/vespa-logomark-tiny.png)recommendation tutorial](news/) is a good starting point.

Finally, [search as you type and query suggestions](#search-as-you-type-and-query-suggestions)
lets users quickly create good queries.



## Other sample applications and demos


### Search as you type and query suggestions
[![logo](/assets/vespa-logomark-tiny.png) Incremental Search](incremental-search/) shows search-as-you-type functionality,
where for each keystroke of the user, it retrieves matching documents.
It also demonstrates search suggestions (query auto-completion).


### Vespa as ML inference server
[![logo](/assets/vespa-logomark-tiny.png) Stateless model evaluation](model-inference/) demonstrates
using Vespa as a stateless ML model inference server
where Vespa takes care of distributing ML models to multiple serving containers,
offering horizontal scaling and safe deployment.
It features model versioning and a feature processing pipeline,
as well as using custom code in [Searchers](https://docs.vespa.ai/en/searcher-development.html),
[Document Processors](https://docs.vespa.ai/en/document-processing.html?mode=cloud) and
[Request Handlers](https://docs.vespa.ai/en/jdisc/developing-request-handlers.html).


### Vespa Documentation Search
[![logo](/assets/vespa-logomark-tiny.png) Vespa Documentation Search](https://github.com/vespa-cloud/vespa-documentation-search)
is the search application that powers [search.vespa.ai](https://search.vespa.ai/) -
refer to this for GitHub Actions automation.
This sample app is a good start for [automated deployments](https://cloud.vespa.ai/en/automated-deployments),
as it has system, staging and production test examples.
It uses the [Document API](https://docs.vespa.ai/en/document-api-guide.html)
both for regular PUT operations but also for UPDATE with _create-if-nonexistent_.
It also has [Vespa Components](https://github.com/vespa-cloud/vespa-documentation-search/tree/main/src/main/java/ai/vespa/cloud/docsearch)
for custom code.


### CORD-19 Search
[![logo](/assets/vespa-logomark-tiny.png) cord19.vespa.ai](https://cord19.vespa.ai/) is a full-featured application,
based on the [Covid-19 Open Research Dataset](https://huggingface.co/datasets/allenai/cord19):
* [cord-19](https://github.com/vespa-engine/cord-19): frontend
* [cord-19-search](https://github.com/vespa-cloud/cord-19-search): search backend

This application uses embeddings to implement "similar documents" search.

----

Note: Applications with _pom.xml_ are Java/Maven projects and must be built before deployment.
Refer to the [Developer Guide](https://docs.vespa.ai/en/developer-guide.html) for more information.

[Contribute](https://github.com/vespa-engine/vespa/blob/master/CONTRIBUTING.md) to the Vespa sample applications.

----

[![Vespa Sampleapps Search Feed](https://github.com/vespa-engine/sample-apps/actions/workflows/feed.yml/badge.svg)](https://github.com/vespa-engine/sample-apps/actions/workflows/feed.yml)

[![sample-apps link checker](https://api.screwdriver.cd/v4/pipelines/7038/link-checker-sample-apps/badge)](https://cd.screwdriver.cd/pipelines/7038/)

[![sample-apps build](https://api.screwdriver.cd/v4/pipelines/7038/build-apps/badge)](https://cd.screwdriver.cd/pipelines/7038/)

[![sample-apps verify-guides](https://api.screwdriver.cd/v4/pipelines/7038/verify-guides/badge)](https://cd.screwdriver.cd/pipelines/7038/)
[![sample-apps verify-guides-big](https://api.screwdriver.cd/v4/pipelines/7038/verify-guides-big/badge)](https://cd.screwdriver.cd/pipelines/7038/)
